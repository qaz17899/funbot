"""Import parsed route data into database.

This script reads routes_data.json (generated by parse_routes.py) and
imports the data into RouteData and RouteRequirement tables using
recursive insertion for the requirement tree structure.

Data Cleaning:
- Unescape characters (Bill\\'s → Bill's)
- Parse weather/day_of_week raw strings
- Mark DevelopmentRequirement routes as is_implemented=False

Usage:
    python scripts/import_routes.py
"""

from __future__ import annotations

import asyncio
import json
import logging
import re
import sys
from pathlib import Path
from typing import Any

# Add project root to path (scripts/importers/ -> funbot root)
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from tortoise import Tortoise

from funbot.db.models.pokemon.route_data import RouteData
from funbot.db.models.pokemon.route_requirement import (
    RequirementType,
    RouteRequirement,
    SpecialRoutePokemon,
)

logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger(__name__)


# =============================================================================
# REQUIREMENT TYPE MAPPING
# =============================================================================

REQUIREMENT_TYPE_MAP: dict[str, RequirementType] = {
    "RouteKillRequirement": RequirementType.ROUTE_KILL,
    "GymBadgeRequirement": RequirementType.GYM_BADGE,
    "ClearDungeonRequirement": RequirementType.DUNGEON_CLEAR,
    "TemporaryBattleRequirement": RequirementType.TEMP_BATTLE,
    "QuestLineCompletedRequirement": RequirementType.QUEST_LINE_COMPLETED,
    "QuestLineStepCompletedRequirement": RequirementType.QUEST_LINE_STEP,
    "ObtainedPokemonRequirement": RequirementType.OBTAINED_POKEMON,
    "WeatherRequirement": RequirementType.WEATHER,
    "DayOfWeekRequirement": RequirementType.DAY_OF_WEEK,
    "SpecialEventRequirement": RequirementType.SPECIAL_EVENT,
    "ItemOwnedRequirement": RequirementType.ITEM_OWNED,
    "StatisticRequirement": RequirementType.STATISTIC,
    "PokemonLevelRequirement": RequirementType.POKEMON_LEVEL,
    "OneFromManyRequirement": RequirementType.ONE_FROM_MANY,
    "MultiRequirement": RequirementType.MULTI,
}

# Types that indicate incomplete/development features
DEVELOPMENT_REQUIREMENT_TYPES = {"DevelopmentRequirement", "SpecialEventRandomRequirement"}

# Regex for extracting dungeon names from getDungeonIndex('Name')
DUNGEON_INDEX_PATTERN = re.compile(r"getDungeonIndex\(['\"](.+?)['\"]\)")


# =============================================================================
# DATA CLEANING FUNCTIONS
# =============================================================================


def clean_string(s: str) -> str:
    """Unescape characters and extract wrapped values.

    Handles:
    - Bill\\'s → Bill's
    - getDungeonIndex('Mt. Moon') → Mt. Moon
    """
    if not s:
        return s

    # Extract dungeon name from getDungeonIndex wrapper
    dungeon_match = DUNGEON_INDEX_PATTERN.search(s)
    if dungeon_match:
        s = dungeon_match.group(1)

    # Unescape quotes
    return s.replace("\\'", "'").replace('\\"', '"')


def clean_params(params: dict[str, Any]) -> dict[str, Any]:
    """Clean parameters dictionary."""
    cleaned = {}
    for key, value in params.items():
        if isinstance(value, str):
            cleaned[key] = clean_string(value)
        elif isinstance(value, dict):
            cleaned[key] = clean_params(value)
        else:
            cleaned[key] = value
    return cleaned


def parse_weather_raw(raw: str) -> list[str]:
    """Parse weather raw string: '[WeatherType.Clear, WeatherType.Overcast]' → ['Clear', 'Overcast']."""
    if not raw:
        return []
    # Remove brackets and split
    raw = raw.strip("[]")
    items = [item.strip() for item in raw.split(",")]
    # Extract type name after the dot
    return [item.split(".")[-1] for item in items if "." in item]


def parse_day_of_week_raw(raw: str) -> list[str]:
    """Parse day of week raw string: '[DayOfWeek.Monday]' → ['Monday']."""
    return parse_weather_raw(raw)  # Same format


def has_development_requirement(node: dict[str, Any]) -> bool:
    """Check if a requirement tree contains DevelopmentRequirement."""
    if node.get("type") in DEVELOPMENT_REQUIREMENT_TYPES:
        return True
    for child in node.get("children", []):
        if has_development_requirement(child):
            return True
    return False


def clean_pokemon_list(names: list[str]) -> list[str]:
    """Clean Pokemon name list."""
    return [clean_string(name) for name in names if name.strip()]


# =============================================================================
# RECURSIVE REQUIREMENT SAVER
# =============================================================================


async def save_requirement_tree(
    node: dict[str, Any], route: RouteData | None = None, parent: RouteRequirement | None = None
) -> RouteRequirement | None:
    """Recursively save a requirement node and its children."""
    req_type_str = node.get("type", "")
    req_type = REQUIREMENT_TYPE_MAP.get(req_type_str)

    # Skip development requirements (they're not implementable)
    if req_type_str in DEVELOPMENT_REQUIREMENT_TYPES:
        return None

    if req_type is None:
        # Unknown requirement type - store with _unknown flag
        req_type = RequirementType.ROUTE_KILL  # Fallback
        logger.warning(f"Unknown requirement type: {req_type_str}")

    # Clean and transform parameters
    params = clean_params(node.get("params") or {})

    # Transform raw weather/day strings to arrays
    if req_type == RequirementType.WEATHER and "raw" in params:
        params["weather_types"] = parse_weather_raw(params.pop("raw"))
    elif req_type == RequirementType.DAY_OF_WEEK and "raw" in params:
        params["days"] = parse_day_of_week_raw(params.pop("raw"))

    # Store original type if unknown
    if req_type_str not in REQUIREMENT_TYPE_MAP:
        params["_original_type"] = req_type_str

    # Create the requirement node
    db_node = await RouteRequirement.create(
        route=route, parent=parent, requirement_type=req_type, parameters=params
    )

    # Recursively save children
    for child_data in node.get("children", []):
        await save_requirement_tree(child_data, route=None, parent=db_node)

    return db_node


# =============================================================================
# MAIN IMPORT FUNCTION
# =============================================================================


async def import_routes() -> None:
    """Import all routes from routes_data.json."""
    json_path = Path(__file__).parent.parent / "data" / "routes_data.json"

    if not json_path.exists():
        logger.error(f"Error: {json_path} not found. Run parse_routes.py first.")
        return

    routes_data = json.loads(json_path.read_text(encoding="utf-8"))

    logger.info(f"Importing {len(routes_data)} routes...")

    # Track stats
    stats = {"routes": 0, "requirements": 0, "special_pokemon": 0, "skipped_dev": 0}

    for route_data in routes_data:
        # Check if route has development requirements (mark as not implemented)
        is_implemented = True
        for req in route_data.get("requirements", []):
            if has_development_requirement(req):
                is_implemented = False
                stats["skipped_dev"] += 1
                break

        # Clean Pokemon lists
        land = clean_pokemon_list(route_data["pokemon"]["land"])
        water = clean_pokemon_list(route_data["pokemon"]["water"])
        headbutt = clean_pokemon_list(route_data["pokemon"]["headbutt"])

        # Create RouteData
        route = await RouteData.create(
            region=route_data["region"],
            number=route_data["number"],
            name=clean_string(route_data["name"]),
            order_number=route_data.get("order_number", route_data["number"]),
            sub_region=route_data.get("sub_region"),
            custom_health=route_data.get("route_health"),
            land_pokemon=land,
            water_pokemon=water,
            headbutt_pokemon=headbutt,
            is_implemented=is_implemented,
        )
        stats["routes"] += 1

        # Create root requirements (skip dev requirements)
        for req_data in route_data.get("requirements", []):
            if not has_development_requirement(req_data):
                result = await save_requirement_tree(req_data, route=route, parent=None)
                if result:
                    stats["requirements"] += 1

        # Create special Pokemon entries
        for special_data in route_data["pokemon"].get("special", []):
            # Skip if requirement has development flag
            if special_data.get("requirement") and has_development_requirement(
                special_data["requirement"]
            ):
                continue

            # Save the requirement tree if exists
            root_req = None
            if special_data.get("requirement"):
                root_req = await save_requirement_tree(
                    special_data["requirement"], route=None, parent=None
                )
                if root_req:
                    stats["requirements"] += 1

            await SpecialRoutePokemon.create(
                route=route,
                pokemon_names=clean_pokemon_list(special_data.get("pokemon", [])),
                root_requirement=root_req,
            )
            stats["special_pokemon"] += 1

        if stats["routes"] % 50 == 0:
            logger.info(f"  Progress: {stats['routes']}/{len(routes_data)} routes")

    logger.info("\n✅ Import complete!")
    logger.info(f"   - Routes: {stats['routes']}")
    logger.info(f"   - Requirements: {stats['requirements']}")
    logger.info(f"   - Special Pokemon: {stats['special_pokemon']}")
    if stats["skipped_dev"] > 0:
        logger.info(f"   - Routes with dev requirements: {stats['skipped_dev']}")


async def main() -> None:
    """Initialize database and run import with transaction wrapper."""
    from tortoise.transactions import in_transaction

    from funbot.db.config import TORTOISE_CONFIG

    # Initialize Tortoise ORM with project config
    await Tortoise.init(config=TORTOISE_CONFIG)

    # safe=True won't drop existing tables
    await Tortoise.generate_schemas(safe=True)

    try:
        # Use transaction for atomicity and performance
        async with in_transaction():
            await import_routes()
        logger.info("✅ Transaction committed successfully!")
    except Exception as e:
        logger.exception("❌ Import failed, transaction rolled back: %s", e)
        raise
    finally:
        await Tortoise.close_connections()


if __name__ == "__main__":
    asyncio.run(main())
